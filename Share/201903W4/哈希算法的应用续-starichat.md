如今分布式技术发展的很成熟，应用也很广泛。web方面的岗位也基本都会问到分布式的问题。那么今天的哈希算法也正好就是用来解决分布式问题。

## 1.负载均衡
什么是负载均衡，这里有一篇很详细的介绍文章。[什么是负载均衡](https://zhuanlan.zhihu.com/p/32841479)

负载均衡的实现方式有很多种：
1.重定向：将请求全部发送到前置机，由前置机通过算法得到要分配给那台应用服务器，然后响应给客户端，由客户端重定向到应用服务器的一种方式。
2.反向代理：通过在前置机，使用反向代理的方式，将请求分发到应用服务器，客户端无需再请求一次，实现方式通常有两种，一种是用交换机实现，还有一种是用ngnix实现。
3.数据链路返回
这种方式，通过给应用服务器设置虚拟ip，然后通过修改mac地址的方式，将请求分发出去，而应用服务器收到请求后，可以直接响应给客户端，而不需要经过前置机。

负载均衡的算法有很多，有轮询，随机，加权轮询等。如何才能实现一个会话粘滞的负载均衡的算法？也就是说，在同一个客户端上，在一次会话中的所有请求都路由到服务器上。

最直接的方法就是，维护一张映射关系表，这张表的内容是客户端IP地址或者会话ID与服务器编号的映射关系。客户端发出的每次请求，都要现在映射表中查找对应路由到服务器编号，然后再请求编号对应的服务器。这种方法简单直观，但也有好多弊端。

- 如果客户端很多，映射表可能会很大，比较浪费内存空间。
- 客户端下线，上线，服务器扩容，缩容都会导致映射失效，这样维护映射表的成本就会很大

如果借助哈希算法，这些问题可以被解决。通过哈西算法，对客户端ip地址或者会话id计算哈希值，将取得哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到服务器编号。

## 2.数据分片
哈希算法可以用于数据分片。
1.如何统计“搜索关键词”出现的次数？
假如我们有很大的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

主要有两个难点：
- 搜索日志很大，没法放到一台机器的内存中
- 如果只用一台机器看来处理这么巨大的数据，处理时间会很长。

针对以上难点，我们对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。具体的思路是这样的：为了提高处理的速度，我们用n台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再根 n 取模，最终得到的值，就是应该被分配到的机器编号。

这样，哈希值相同的搜索关键词就被分配到了同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

### 如何快速判断图片是否在图库中。
如何快速判断图片是否在图库中？上一节我们讲过这个例子，不知道你还记得吗？当时我介绍了一种方法，即给每个图片取唯一标识，然后构建散列表。

假设现在我们图库中有一亿张图片，很显然，在单台机器的内存有限，而一亿张图片构建散列表显然远远超过了单台机器的内存上线。

解决方案：我们对数据进行分片，然后采用多机处理，让每台机器只维护一部分图片对应的散列表。我们每次从图库中读取一张图片计算唯一标识，然后与机器数求余取模，得到的值就是要分配的机器编号。然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。


